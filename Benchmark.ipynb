{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark of methods for brain tumor segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nibabel as nib\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from skfuzzy.cluster import cmeans\n",
    "from dipy.segment.mask import median_otsu\n",
    "from time import time\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "N_ITERS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "NUMPASS = 5\n",
    "MEDIAN_RADIUS = 11\n",
    "HIT = 0.25\n",
    "BLUR_RADIUS = 3\n",
    "\n",
    "\n",
    "N_CLUSTERS = 5\n",
    "N_COMPONENTS = 2\n",
    "\n",
    "M = 2.0\n",
    "EPS = 0.01\n",
    "MAX_IT = 100\n",
    "    \n",
    "K1 = np.ones((3, 3), np.uint16)\n",
    "\n",
    "IMG_ROOT = '/Users/macbook/Documents/Education/4_Year/DiplomaWork/Images/brain/TCIA Low grade glioma/nifti/'\n",
    "\n",
    "def get_data(root, patients):\n",
    "    for patient in iter(patients):\n",
    "        img_path = root + 'LGG-%s/LGG-%s_T2.nii.gz' % (patient[0], patient[0])\n",
    "        seg_path = root + 'LGG-%s/LGG-%s-Segmentation.nii.gz' % (patient[0], patient[0])\n",
    "        img = nib.load(img_path).get_data()[:, :, patient[1]]\n",
    "        seg = nib.load(seg_path).get_data()[:, :, patient[1]]\n",
    "        yield (img, seg)\n",
    "    \n",
    "def draw(img, size=(8, 8), cmap='jet'):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.plot()\n",
    "    \n",
    "\n",
    "\n",
    "# from random import shuffle\n",
    "\n",
    "# def get_data():\n",
    "#     NUM = 0\n",
    "#     for img_path, seg_path in zip(glob.glob(IMG_ROOT + '/**/*T2.nii.gz'), glob.glob(IMG_ROOT + '/**/*Segmentation.nii.gz')):\n",
    "#         img = nib.load(img_path).get_data()\n",
    "#         seg = nib.load(seg_path).get_data()\n",
    "#         s = np.sum(seg.reshape((seg.shape[2], -1)).astype(np.int32), axis=1)\n",
    "#         indicies = s > 0\n",
    "#         LEN = indicies.shape[0]\n",
    "#         NUM += LEN\n",
    "#         indicies = indicies.reshape((-1))\n",
    "#         if NUM > LIMIT:\n",
    "#             raise StopIteration\n",
    "#         else:\n",
    "#             print(s)\n",
    "#             indicies = np.argwhere(indicies).reshape(-1)\n",
    "#             print(indicies)\n",
    "#             img2 = img[:, :, indicies]\n",
    "            \n",
    "#             seg2 = seg[:, :, indicies]\n",
    "            \n",
    "#             print(seg2.shape)\n",
    "#             print(np.sum(seg2.reshape((seg2.shape[2], -1)).astype(np.int32), axis=1))\n",
    "#             yield img2[:, :, 4], seg2[:, :, 4]\n",
    "        \n",
    "\n",
    "        \n",
    "def preprocess(data):\n",
    "    for data_ in iter(data):\n",
    "        img = data_[0].astype(np.float32)\n",
    "        img = cv.medianBlur(img, 3)\n",
    "        img, _ = median_otsu(img, numpass=NUMPASS, median_radius=MEDIAN_RADIUS)\n",
    "        original_shape = img.shape\n",
    "        img = ((img - np.min(img)) / (np.max(img) - np.min(img))).astype(np.float32)\n",
    "        blurred = cv.blur(img, (19, 19))\n",
    "        edges = np.clip(img - blurred, 0.0, 1.0)\n",
    "        edges[edges > HIT] = 1.0\n",
    "        edges[edges <= HIT] = 0.0\n",
    "        edges = cv.dilate(edges, np.ones((2, 2)), iterations=1)\n",
    "        img = np.clip(img - edges, 0.0, 1.0)\n",
    "        yield (img, data_[1])\n",
    "    \n",
    "PATIENTS = [\n",
    "    ('104', 38),  \n",
    "#     ('220', 25),\n",
    "#     ('225', 35),\n",
    "#     ('229', 14),\n",
    "#     ('249', 35),\n",
    "#     ('374', 45),\n",
    "#     ('600', 25),\n",
    "#     ('500', 33),\n",
    "#     ('547', 39),\n",
    "#     ('311', 39),\n",
    "#     (357, 35),\n",
    "#     (387, 16),\n",
    "#     (345, 30),\n",
    "#     (346, 48),\n",
    "#     (351, 24),\n",
    "#     (354, 28),\n",
    "#     (355, 40),\n",
    "#     (357, 36),\n",
    "#     (359, 33),\n",
    "#     (360, 24),\n",
    "#     (361, 19),\n",
    "#     (363, 23),\n",
    "#     (365, 28),\n",
    "#     (367, 28),\n",
    "#     (371, 35),\n",
    "#     (373, 34),\n",
    "#     (374, 44),\n",
    "#     (375, 43),\n",
    "#     (377, 38),\n",
    "#     (380, 37),\n",
    "#     (383, 38),\n",
    "#     (385, 36),\n",
    "#     (388, 43),\n",
    "#     (391, 25),\n",
    "#     (394, 38),\n",
    "#     (396, 37),\n",
    "#     (492, 40),\n",
    "#     (500, 34),\n",
    "#     (506, 26),\n",
    "#     (515, 25),\n",
    "#     (516, 43),\n",
    "#     (518, 49),\n",
    "#     (519, 23),\n",
    "    (520, 33),\n",
    "] \n",
    "\n",
    "N = len(PATIENTS)\n",
    "print(N)\n",
    "\n",
    "DATA = list(get_data(IMG_ROOT, PATIENTS))\n",
    "PREP = list(preprocess(DATA))\n",
    "\n",
    "# INDEX = 0\n",
    "# orig = DATA[INDEX][0]\n",
    "# # image = PREP[INDEX][0]\n",
    "# gt = DATA[INDEX][1]\n",
    "\n",
    "# # res, labels = multivariate_kmeans(image)\n",
    "# # print('Dice (%)', calc_dice(res, gt))\n",
    "# # draw(orig)\n",
    "# # # draw(labels)\n",
    "# # # draw(res)\n",
    "# # draw(gt)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.imshow(orig, 'gray')\n",
    "# plt.imshow(gt, alpha=0.3)\n",
    "\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(img, n_clusters):\n",
    "    img = cv.blur(img, (15, 15))\n",
    "    x = img.reshape((-1, 1))\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=0, algorithm='full', precompute_distances=False, n_init=1)\n",
    "    model.fit(x)\n",
    "    c_index = np.argmax(model.cluster_centers_.reshape((-1)))\n",
    "    flat = np.full(img.shape[0] * img.shape[1], 0, dtype=np.uint8)\n",
    "    flat[model.labels_ == c_index] = 1\n",
    "    mask = flat.reshape(img.shape)\n",
    "    mask = cv.dilate(mask, K1, iterations=1)\n",
    "    mask = cv.erode(mask, K1, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Multivariate K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_kmeans(img, n_clusters):\n",
    "    f1 = cv.blur(img, (7, 7)).reshape((-1, 1))\n",
    "    f2 = cv.blur(img, (9, 9)).reshape((-1, 1)) \n",
    "    f3 = cv.blur(img, (5, 5)).reshape((-1, 1)) \n",
    "    f4 = img.reshape((-1, 1)) * 0.45\n",
    "    xc = np.linspace(0, 1.0, img.shape[1])\n",
    "    yc = np.linspace(0, 1.0, img.shape[0])\n",
    "    f5 = np.transpose([np.tile(xc, len(xc)), np.repeat(yc, len(yc))]).reshape((-1, 2)) * 0.015\n",
    "    f3 = cv.blur(img, (5, 5)).reshape((-1, 1)) \n",
    "    X = np.concatenate((f1, f2, f3, f4, f5), axis=1)\n",
    "    x = X\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=0, algorithm='full', precompute_distances=False, n_init=1)\n",
    "    model.fit(x)\n",
    "    c_index = np.argmax(model.cluster_centers_[:,3])\n",
    "    flat = np.full(img.shape[0] * img.shape[1], 0, dtype=np.uint8)\n",
    "    flat[model.labels_ == c_index] = 1\n",
    "    mask = flat.reshape(img.shape)\n",
    "    mask = cv.erode(mask, K1, iterations=1)\n",
    "    mask = cv.dilate(mask, K1, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy C Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcm(img, n_clusters):\n",
    "    M = 2\n",
    "    img = cv.blur(img, (15, 15))\n",
    "    flat = img.reshape((1, -1))\n",
    "    c, u, a1, a2, a3, a4, a5 = cmeans(flat, n_clusters, M, EPS, 50)\n",
    "    tumor_index = np.argmax(c, axis=0)\n",
    "    defuz = np.argmax(u, axis=0)\n",
    "    mask = np.full(defuz.shape[0], 0, dtype=np.uint16)\n",
    "    mask[defuz == tumor_index] = 1\n",
    "    mask = mask.reshape(img.shape)\n",
    "    mask = cv.erode(mask, K1, iterations=1)\n",
    "    mask = cv.dilate(mask, K1, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture(img, n_components):\n",
    "    img = cv.blur(img, (15, 15))\n",
    "    x = img.reshape((-1, 1))\n",
    "    model = GaussianMixture(n_components=n_components, covariance_type='spherical')\n",
    "    model.fit(x)\n",
    "    labels = model.predict(x)\n",
    "    c_index = np.argmax(model.means_)\n",
    "    flat = np.full(img.shape[0] * img.shape[1], 0, dtype=np.uint8)\n",
    "    flat[labels == c_index] = 1\n",
    "    mask = flat.reshape(img.shape)\n",
    "    mask = cv.erode(mask, K1, iterations=1)\n",
    "    mask = cv.dilate(mask, K1, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_cpu(img, max_it=100, eps=0.001):\n",
    "    cols = img.shape[1]\n",
    "\n",
    "    mid = cols // 2\n",
    "    p1 = img[:, :mid].reshape((-1))\n",
    "    p2 = img[:, mid:].reshape((-1))\n",
    "    img = img.reshape((-1))\n",
    "\n",
    "    it = -1\n",
    "    while True:\n",
    "        t1 = np.mean(p1)\n",
    "        t2 = np.mean(p2)\n",
    "\n",
    "        t = (t1 + t2) / 2.0\n",
    "        it += 1\n",
    "        if it >= max_it or abs(t1 - t2) <= eps:\n",
    "            return t\n",
    "        else:\n",
    "            p1 = img[img < t]\n",
    "            p2 = img[img >= t]\n",
    "        \n",
    "def threshold(img):\n",
    "    t = find_threshold_cpu(img, max_it=MAX_IT, eps=EPS)\n",
    "    mask = (img > t).astype(np.int16)\n",
    "    mask = cv.erode(mask, K1, iterations=1)\n",
    "    mask = cv.dilate(mask, K1, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from dipy.segment.mask import median_otsu\n",
    "from pydicom import Dataset\n",
    "\n",
    "from jinja2 import Template\n",
    "import numpy as np\n",
    "\n",
    "BLOCKDIM = 1024\n",
    "\n",
    "SRC = '''\n",
    "    #define N {{N}}\n",
    "    #define BLOCKDIM 1024\n",
    "    \n",
    "    struct Cluster{\n",
    "        float sum;\n",
    "        int count;\n",
    "    };\n",
    "    \n",
    "    __device__ Cluster clusters_d[(N + BLOCKDIM - 1) / BLOCKDIM];\n",
    "    \n",
    "    __device__ float euclidian_dist(const float a, const float b){\n",
    "        float dist = a - b;\n",
    "        return hypotf(dist, dist);\n",
    "    }\n",
    "    \n",
    "    __global__ void relabel(const float* src, const float* clusters, int n, int nClusters, int* labels){\n",
    "        int pos = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        if(pos < n){\n",
    "            float minDist = 1.0f;\n",
    "            int clusterIndex = 0;\n",
    "            for(int c = 0; c < nClusters; c++){\n",
    "                float dist = euclidian_dist(src[pos], clusters[c]);\n",
    "                if(dist <= minDist){\n",
    "                    clusterIndex = c;\n",
    "                    minDist = dist;\n",
    "                }\n",
    "            }\n",
    "            labels[pos] = clusterIndex;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    __global__ void calculateClusters(const float* src, const int* labels, int n, int clusterIndex){\n",
    "        extern __shared__ Cluster _clusters[];\n",
    "        int pos = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        int tid = threadIdx.x;\n",
    "        _clusters[tid] = Cluster();\n",
    "        _clusters[tid].sum = 0.0f;\n",
    "        _clusters[tid].count = 0;\n",
    "        if(pos < n && labels[pos] == clusterIndex){\n",
    "            _clusters[tid].sum = src[pos];\n",
    "            _clusters[tid].count = 1;\n",
    "        }\n",
    "        __syncthreads();\n",
    "        for(unsigned int stride = blockDim.x / 2; stride > 0; stride /= 2){\n",
    "            if(threadIdx.x < stride){\n",
    "                _clusters[tid].sum += _clusters[tid + stride].sum;\n",
    "            }\n",
    "            __syncthreads();\n",
    "            if(threadIdx.x < stride){\n",
    "                _clusters[tid].count += _clusters[tid + stride].count;\n",
    "            }\n",
    "            __syncthreads();\n",
    "        }\n",
    "        __syncthreads();\n",
    "        if(threadIdx.x == 0){\n",
    "            clusters_d[blockIdx.x].sum = _clusters[0].sum;\n",
    "            clusters_d[blockIdx.x].count = _clusters[0].count;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    __global__ void findCenters(int n, int clusterIndex, float* dst){\n",
    "        extern __shared__ Cluster _clusters[];\n",
    "        int pos = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        int tid = threadIdx.x;\n",
    "        _clusters[tid] = clusters_d[pos];\n",
    "        __syncthreads();\n",
    "        for(unsigned int stride = blockDim.x / 2; stride > 0; stride /= 2){\n",
    "            if(tid < stride){\n",
    "                _clusters[tid].sum += _clusters[tid + stride].sum;\n",
    "            }\n",
    "            __syncthreads();\n",
    "            if(tid < stride){\n",
    "                _clusters[tid].count += _clusters[tid + stride].count;\n",
    "            }\n",
    "            __syncthreads();\n",
    "        }\n",
    "        __syncthreads();\n",
    "        if(tid == 0){\n",
    "            dst[clusterIndex] = _clusters[0].count > 0 ? _clusters[0].sum / (_clusters[0].count * 1.0f) : 0.0f;\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "\n",
    "def cuda_kmeans(img, **kwargs):\n",
    "        w = img.shape[1]\n",
    "        h = img.shape[0]\n",
    "        n = w * h\n",
    "        max_it = 30\n",
    "        n_clusters = kwargs.get('n_clusters', 3)\n",
    "        blur_radius = kwargs.get('blur_radius', 5)\n",
    "\n",
    "        img = cv.blur(img, (13, 13))\n",
    "        src = img.reshape((-1))\n",
    "\n",
    "        module = SourceModule(Template(SRC).render(N=n))\n",
    "        relabel = module.get_function('relabel')\n",
    "        calculate_clusters = module.get_function('calculateClusters')\n",
    "        find_centers = module.get_function('findCenters')\n",
    "\n",
    "        t0 = time() * 1000\n",
    "        centers = np.random.rand(n_clusters).astype(np.float32)\n",
    "\n",
    "        # Image\n",
    "        src_gpu = cuda.mem_alloc(src.nbytes)\n",
    "        cuda.memcpy_htod(src_gpu, src)\n",
    "\n",
    "        # Cluster centers\n",
    "\n",
    "        centers_gpu = cuda.mem_alloc(centers.nbytes)\n",
    "        cuda.memcpy_htod(centers_gpu, centers)\n",
    "\n",
    "        # Labels\n",
    "        labels = np.empty_like(src).astype(np.int32)\n",
    "        labels_gpu = cuda.mem_alloc(labels.nbytes)\n",
    "        cuda.memcpy_htod(labels_gpu, labels)\n",
    "        \n",
    "        start = cuda.Event()\n",
    "        end = cuda.Event()\n",
    "        \n",
    "        t1 = time() * 1000\n",
    "        \n",
    "        start.record()\n",
    "        for it in range(max_it):\n",
    "            relabel(src_gpu, centers_gpu, np.int32(n), np.int32(n_clusters), labels_gpu,\n",
    "                    block=(BLOCKDIM, 1, 1), grid=((n + BLOCKDIM - 1) // BLOCKDIM, 1))\n",
    "            for c in range(n_clusters):\n",
    "                calculate_clusters(src_gpu, labels_gpu, np.int32(n), np.int32(c),\n",
    "                                   block=(BLOCKDIM, 1, 1), grid=((n + BLOCKDIM - 1) // BLOCKDIM, 1),\n",
    "                                   shared=8 * BLOCKDIM)\n",
    "                find_centers(np.int32(n), np.int32(c), centers_gpu,\n",
    "                             block=((n + BLOCKDIM - 1) // BLOCKDIM, 1, 1), grid=((1, 1)),\n",
    "                             shared=8 * (n + BLOCKDIM - 1) // BLOCKDIM)\n",
    "\n",
    "        \n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "        msecs = end.time_since(start)*1e-3\n",
    "        msecs *= 1000\n",
    "        msecs += t1 - t0\n",
    "        \n",
    "        t0 = time() * 1000\n",
    "        cuda.memcpy_dtoh(labels, labels_gpu)\n",
    "        cuda.memcpy_dtoh(centers, centers_gpu)\n",
    "#\n",
    "        labels = labels.reshape((-1))\n",
    "        c_index = np.argmax(centers)\n",
    "        flat = np.full(n, 0, dtype=np.uint8)\n",
    "        flat[labels == c_index] = 1\n",
    "        mask = flat.reshape((h, w))\n",
    "        mask = cv.erode(mask, kernel=K1, iterations=1)\n",
    "        mask = cv.dilate(mask, kernel=K1, iterations=1)\n",
    "        t1 = time() * 1000\n",
    "        msecs += t1 - t0\n",
    "        return mask, msecs\n",
    "\n",
    "cuda_kmeans.is_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile average time and accuracy (Dice-Sørensen) per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGS = {\n",
    "#     'K Means': kmeans,\n",
    "# #     'Threshold': threshold,\n",
    "#     'Gaussian Mixture': gaussian_mixture,\n",
    "# #     'Fuzzy C Means': fcm,\n",
    "# #     'Multivariate K Means': multivariate_kmeans\n",
    "# }\n",
    "\n",
    "import collections\n",
    "ALGS = collections.OrderedDict()\n",
    "ALGS['K Means'] = kmeans\n",
    "# ALGS['Fuzzy C Means'] = fcm\n",
    "# ALGS['Gaussian Mixture'] = gaussian_mixture\n",
    "# ALGS['Multivariate K Means'] = multivariate_kmeans\n",
    "ALGS['CUDA K Means'] = cuda_kmeans\n",
    "\n",
    "\n",
    "def t(alpha, gl):\n",
    "    return scipy.stats.t.ppf(1-(alpha/2), gl)\n",
    "\n",
    "TP_INDEX = 0\n",
    "FP_INDEX = 1\n",
    "FN_INDEX = 2\n",
    "DC_INDEX = 3\n",
    "PR_INDEX = 4\n",
    "RC_INDEX = 5\n",
    "F1_INDEX = 6\n",
    "\n",
    "def calc_accuracy(seg, gt):\n",
    "    size = seg.shape[0] * seg.shape[1]\n",
    "    tp = np.sum(seg[gt==1])\n",
    "    tn = np.sum(seg[gt==0])\n",
    "    \n",
    "    fp = np.sum((gt==0) & (seg==1))\n",
    "    fn = np.sum((gt==1) & (seg==0))\n",
    "    dc = 2.0 * tp / (np.sum(gt) + np.sum(seg)) * 100.0\n",
    "    \n",
    "#     dc = 2 * tp / (2 * tp + fp + fn) * 100.0\n",
    "#     precision = tp / (tp + fp) \n",
    "#     recall = tp / (tp + fn)\n",
    "#     f1 = 2 * precision * recall / (precision + recall) * 100.0\n",
    "\n",
    "    precision = tp / (tp + fp) * 100.0 \n",
    "    recall = tp / (tp + fn) * 100.0\n",
    "\n",
    "    tp = tp * 100.0 / size\n",
    "    fp = fp * 100.0 / size\n",
    "    fn = fn * 100.0 / size\n",
    "    return dc\n",
    "\n",
    "def profile(alg, data, n_clusters):\n",
    "    avg_time = []\n",
    "    avg_accuracy = []\n",
    "    for data_item in iter(data):\n",
    "        time_it = []\n",
    "        accuracy_it = []\n",
    "        img, gt = data_item[0], data_item[1]\n",
    "        for i in range(N_ITERS):\n",
    "            duration = 0.0\n",
    "            if getattr(alg, 'is_cuda', False):\n",
    "                seg, duration = alg(img)\n",
    "            else:\n",
    "                t0 = time()\n",
    "                seg = alg(img, n_clusters)\n",
    "                t1 = time()\n",
    "                duration = (t1 - t0) * 1000.0\n",
    "            \n",
    "            time_it.append([duration])\n",
    "            accuracy_it.append(calc_accuracy(seg, gt))\n",
    "        avg_time.append(np.mean(time_it))\n",
    "        avg_accuracy.append(np.mean(accuracy_it))\n",
    "    return avg_time, avg_accuracy\n",
    "\n",
    "# def profile_cuda(alg, data):\n",
    "#     avg_time = []\n",
    "#     avg_accuracy = []\n",
    "#     for data_item in iter(data):\n",
    "#         time_it = np.asarray([])\n",
    "#         accuracy_it = np.empty((1, 7))\n",
    "#         img, gt = data_item[0], data_item[1]\n",
    "#         for i in range(N_ITERS):\n",
    "            \n",
    "#             time_it.append([(t1 - t0) * 1000.0])\n",
    "#             accuracy_it.append(calc_accuracy(seg, gt))\n",
    "#         avg_time.append(np.mean(time_it))\n",
    "#         avg_accuracy.append(np.mean(accuracy_it, axis=0))\n",
    "#     return avg_time, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "N CLUSTERS =  3\n",
      "================================\n",
      "Average accuracy per image\n",
      "{'K Means': [85.30834340991535, 86.71742808798646], 'CUDA K Means': [85.09732360097324, 85.92150170648463]}\n",
      "\n",
      "\n",
      "================================\n",
      "N CLUSTERS =  4\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "N_CLUSTERS_RANGE = (3, 5)\n",
    "t_avg_accuracy = []\n",
    "conf95_accuracy = []\n",
    "\n",
    "t_avg_time = []\n",
    "conf95_time = []\n",
    "\n",
    "CONF_INT_COEFF = 1.0 / sqrt(N) * t(0.05, N - 1)\n",
    "\n",
    "avg_time_per_n_clusters = []\n",
    "avg_acc_per_n_clusters = []\n",
    "\n",
    "for N_CLUSTERS in range(N_CLUSTERS_RANGE[0], N_CLUSTERS_RANGE[1]):\n",
    "    print('================================')\n",
    "    print('N CLUSTERS = ', N_CLUSTERS)\n",
    "    print('================================')\n",
    "    time_t, accuracy_t = {}, {}\n",
    "    for alg in ALGS.keys():\n",
    "        avg_time, avg_accuracy = profile(ALGS[alg], PREP, N_CLUSTERS)\n",
    "        time_t[alg] = avg_time\n",
    "        accuracy_t[alg] = avg_accuracy\n",
    "\n",
    "#     print('Average time per image')\n",
    "#     print(time_t)\n",
    "#     print('\\n')\n",
    "\n",
    "    print('Average accuracy per image')\n",
    "    print(accuracy_t)\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    t_avg_time_alg = []\n",
    "    t_avg_accuracy_alg = []\n",
    "    conf95_time_alg = []\n",
    "    conf95_accuracy_alg = []\n",
    "    \n",
    "    avg_time_per_alg = []\n",
    "    for alg, time_per_image in time_t.items():\n",
    "        avg_time_per_alg.append(time_per_image)\n",
    "        t_avg_time_ = np.mean(time_per_image)\n",
    "        t_std_time_ = np.std(time_per_image)\n",
    "        t_avg_time_alg.append(t_avg_time_)\n",
    "#         t_std_time[i].append(t_std_time_)\n",
    "        conf95_time_alg.append(\n",
    "            [\n",
    "                t_avg_time_ - t_std_time_ * CONF_INT_COEFF, \n",
    "                t_avg_time_ + t_std_time_ * CONF_INT_COEFF\n",
    "            ]\n",
    "        )\n",
    "    avg_time_per_n_clusters.append(avg_time_per_alg)\n",
    "\n",
    "    avg_acc_per_alg = []\n",
    "    for alg, accuracy_per_image in accuracy_t.items():\n",
    "        avg_acc_per_alg.append(accuracy_per_image)\n",
    "        t_avg_accuracy_ = np.mean(accuracy_per_image)\n",
    "        t_std_accuracy_ = np.std(accuracy_per_image)\n",
    "        t_avg_accuracy_alg.append(t_avg_accuracy_)\n",
    "#         t_std_accuracy[i].append(t_std_accuracy_)\n",
    "        conf95_accuracy_alg.append(\n",
    "            [\n",
    "                t_avg_accuracy_ - t_std_accuracy_ * CONF_INT_COEFF, \n",
    "                t_avg_accuracy_ + t_std_accuracy_ * CONF_INT_COEFF\n",
    "            ]\n",
    "        )\n",
    "    avg_acc_per_n_clusters.append(avg_time_per_alg)\n",
    "    \n",
    "    t_avg_time.append(t_avg_time_alg)\n",
    "    t_avg_accuracy.append(t_avg_accuracy_alg)\n",
    "    conf95_time.append(conf95_time_alg)\n",
    "    conf95_accuracy.append(conf95_accuracy_alg)\n",
    "\n",
    "print('Total average time (msecs)')\n",
    "print(t_avg_time)\n",
    "print('\\n')\n",
    "\n",
    "# print('Total std of time (msecs)^2')\n",
    "# print(t_std_time)\n",
    "# print('\\n')\n",
    "\n",
    "print('95% Confidence interval of time (msecs)')\n",
    "print(conf95_time)\n",
    "print('\\n')\n",
    "\n",
    "print('Total average accuracy (%)')\n",
    "print(t_avg_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "#     print('Total std of accuracy (%)')\n",
    "#     print(t_std_accuracy)\n",
    "#     print('\\n')\n",
    "\n",
    "print('95% Confidence interval of accuracy (%)')\n",
    "print(conf95_accuracy)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "res_time = np.asarray(t_avg_time)\n",
    "res_acc = np.asarray(t_avg_accuracy)\n",
    "conf95_time_res = np.asarray(conf95_time)\n",
    "conf95_acc_res = np.asarray(conf95_accuracy)\n",
    "\n",
    "avg_time_per_n_clusters = np.asarray(avg_time_per_n_clusters)\n",
    "avg_acc_per_n_clusters = np.asarray(avg_acc_per_n_clusters)\n",
    "\n",
    "X = np.arange(N_CLUSTERS_RANGE[0], N_CLUSTERS_RANGE[1])\n",
    "plt.title('Average time (msecs)')\n",
    "plt.xticks(X)\n",
    "plt.xlabel('n clusters')\n",
    "plt.ylabel('msecs')\n",
    "# plt.yscale('log', basey=2)\n",
    "for i, alg in zip(range(len(ALGS.keys())), ALGS.keys()):\n",
    "    # ax.set_xticklabels(['K=%d' % k for k in range(3, 6)])\n",
    "    plt.plot(X, res_time[:,i], label=alg)\n",
    "#     plt.fill_between(X, conf95_time_res[:,i,0], conf95_time_res[:,i,1], alpha=0.15)\n",
    "    # plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('Average accuracy (%)')\n",
    "plt.xticks(X)\n",
    "plt.xlabel('n clusters')\n",
    "plt.ylabel('%')\n",
    "for i, alg in zip(range(len(ALGS.keys())), ALGS.keys()):\n",
    "    # ax.set_xticklabels(['K=%d' % k for k in range(3, 6)])\n",
    "    plt.plot(X, res_acc[:,i], label=alg)\n",
    "#     plt.fill_between(X, conf95_acc_res[:,i,0], conf95_acc_res[:,i,1], alpha=0.15)\n",
    "    # plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import matplotlib\n",
    "palegreen = matplotlib.colors.colorConverter.to_rgb('#8CFF6F')\n",
    "paleblue = matplotlib.colors.colorConverter.to_rgb('#708DFF')\n",
    "    \n",
    "for i, alg in zip(range(len(ALGS.keys())), ALGS.keys()):\n",
    "    fig = plt.figure(1, figsize=(9, 9))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_title('%s - Time (msecs)' % alg)\n",
    "    bp = ax.boxplot(avg_time_per_n_clusters[:,i,:].T)\n",
    "    ax.set_xticklabels(list(range(N_CLUSTERS_RANGE[0], N_CLUSTERS_RANGE[1])))\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(9, 9))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_title('%s - Accuracy (%%)' % alg)\n",
    "    bp = ax.boxplot(avg_acc_per_n_clusters[:,i,:].T)\n",
    "    ax.set_xticklabels(list(range(N_CLUSTERS_RANGE[0], N_CLUSTERS_RANGE[1])))\n",
    "    plt.show()\n",
    "\n",
    "for i, alg in zip(range(len(ALGS.keys())), ALGS.keys()):\n",
    "    print(\"\\n\")\n",
    "    print(\"===========================\")\n",
    "    print('----->', alg, '<-----')\n",
    "    print(\"\\n\")\n",
    "    print('[Average time]')\n",
    "    print(res_time[:,i])\n",
    "    print(\"\\n\")\n",
    "    print('[Average accuracy]')\n",
    "    print(res_acc[:,i])\n",
    "    print(\"\\n\")\n",
    "    print('[Conf 95% time]')\n",
    "    print(conf95_time_res[:,i,:])\n",
    "    print(\"\\n\")\n",
    "    print('[Conf 95% accuracy]')\n",
    "    print(conf95_acc_res[:,i,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile CUDA based algorithms (KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Profile cuda')\n",
    "# CUDA_ALGS = {\n",
    "#     'CUDA K Means': cuda_kmeans\n",
    "# }\n",
    "# time_t, accuracy_t = {}, {}\n",
    "# for alg in CUDA_ALGS.keys():\n",
    "#     avg_time, avg_accuracy = profile_cuda(CUDA_ALGS[alg], PREP)\n",
    "#     time_t[alg] = avg_time\n",
    "#     accuracy_t[alg] = avg_accuracy\n",
    "\n",
    "# print('Average time per image')\n",
    "# print(pd.DataFrame.from_dict(time_t))\n",
    "# print('\\n')\n",
    "\n",
    "# print('Average accuracy per image')\n",
    "# print(pd.DataFrame.from_dict(accuracy_t))\n",
    "# print('\\n')\n",
    "\n",
    "# avg_time = {}\n",
    "# std_time = {}\n",
    "# conf95_time = {}\n",
    "\n",
    "# avg_accuracy = {}\n",
    "# std_accuracy = {}\n",
    "# conf95_accuracy = {}\n",
    "\n",
    "# CONF_INT_COEFF = 1.0 / sqrt(N) * t(0.05, N - 1)\n",
    "\n",
    "# for alg, time_per_image in time_t.items():\n",
    "#     avg_time[alg] = np.mean(time_per_image)\n",
    "#     std_time[alg] = np.std(time_per_image)\n",
    "#     conf95_time[alg] = [\n",
    "#         avg_time[alg] - std_time[alg] * CONF_INT_COEFF,\n",
    "#         avg_time[alg] + std_time[alg] * CONF_INT_COEFF,\n",
    "#     ]\n",
    "    \n",
    "# for alg, accuracy_per_image in accuracy_t.items():\n",
    "#     avg_accuracy[alg] = np.mean(accuracy_per_image)\n",
    "#     std_accuracy[alg] = np.std(accuracy_per_image)\n",
    "#     conf95_accuracy[alg] = [\n",
    "#         avg_accuracy[alg] - std_accuracy[alg] * CONF_INT_COEFF,\n",
    "#         avg_accuracy[alg] + std_accuracy[alg] * CONF_INT_COEFF\n",
    "#     ]\n",
    "\n",
    "# print('Total average time (msecs)')\n",
    "# print(pd.DataFrame.from_dict(avg_time, orient='index'))\n",
    "# print('\\n')\n",
    "\n",
    "# print('Total std of time (msecs)^2')\n",
    "# print(pd.DataFrame.from_dict(std_time, orient='index'))\n",
    "# print('\\n')\n",
    "\n",
    "# print('95% Confidence interval of time (msecs)')\n",
    "# print(pd.DataFrame.from_dict(conf95_time, orient='index'))\n",
    "# print('\\n')\n",
    "\n",
    "# print('Total average accuracy (%)')\n",
    "# print(pd.DataFrame.from_dict(avg_accuracy, orient='index'))\n",
    "# print('\\n')\n",
    "\n",
    "# print('Total std of accuracy (%)')\n",
    "# print(pd.DataFrame.from_dict(std_accuracy, orient='index'))\n",
    "# print('\\n')\n",
    "\n",
    "# print('95% Confidence interval of accuracy (%)')\n",
    "# print(pd.DataFrame.from_dict(conf95_accuracy, orient='index'))\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dipy.segment.mask import otsu\n",
    "# INDEX = 8\n",
    "# img = PREP[INDEX][0]\n",
    "# seg = PREP[INDEX][1]\n",
    "# draw(img)\n",
    "# draw(kmeans(img, 3))\n",
    "# draw(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy.io import load\n",
    "image_data, image_header = load('/Users/macbook/Documents/Education/4_Year/DiplomaWork/Images/brain/BRATS Glioblastoma/BRATS2015_TRAINING/LGG/brats_2013_pat0001_1/VSD.Brain.XX.O.MR_T2.54635/VSD.Brain.XX.O.MR_T2.54635.mha')\n",
    "draw(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
